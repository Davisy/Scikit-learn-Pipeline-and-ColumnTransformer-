{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Chains and Pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of the importance of chaining models, we noticed that we can greatly\n",
    "improve the performance of a kernel SVM on the cancer dataset by using the Min\n",
    "MaxScaler for preprocessing. Here’s code for splitting the data, computing the minimum\n",
    "and maximum, scaling the data, and training the SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:16:24.354323Z",
     "start_time": "2019-05-01T09:15:17.827253Z"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.pipeline import Pipeline \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:17:05.286020Z",
     "start_time": "2019-05-01T09:17:05.073814Z"
    }
   },
   "outputs": [],
   "source": [
    "# load and split the data\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "cancer.data, cancer.target, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:17:08.230658Z",
     "start_time": "2019-05-01T09:17:08.226657Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute minimum and maximum on the training data\n",
    "scaler = MinMaxScaler().fit(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:17:25.273530Z",
     "start_time": "2019-05-01T09:17:25.249930Z"
    }
   },
   "outputs": [],
   "source": [
    "# rescale the training data\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:17:28.362172Z",
     "start_time": "2019-05-01T09:17:28.317971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "# learn an SVM on the scaled training data\n",
    "svm.fit(X_train_scaled, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:17:38.073908Z",
     "start_time": "2019-05-01T09:17:38.046307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.95\n"
     ]
    }
   ],
   "source": [
    "# scale the test data and score the scaled data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Test score: {:.2f}\".format(svm.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s say we want to find better parameters for SVC using GridSearchCV,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:17:59.165194Z",
     "start_time": "2019-05-01T09:17:57.151174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for illustration purposes only, don't use this code!\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:19:24.912445Z",
     "start_time": "2019-05-01T09:19:24.878245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.98\n",
      "Best test set score: 0.97\n",
      "Best parameters:  {'C': 1, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best test set score: {:.2f}\".format(grid.score(X_test_scaled, y_test)))\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pipeline class is a class that allows “gluing” together multiple processing steps into a single scikit-learn estimator.\n",
    "\n",
    "The Pipeline class itself has fit, predict, and score methods and behaves just like any other model in scikit-learn. The most common use case of the Pipeline class is in chaining preprocessing steps (like scaling of the data) together with a supervised model like a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at how we can use the Pipeline class to express the workflow for training\n",
    "an SVM after scaling the data with MinMaxScaler (for now without the grid search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:19:51.287119Z",
     "start_time": "2019-05-01T09:19:51.282118Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a pipeline \n",
    "pipe = Pipeline([('scaler',MinMaxScaler()),('svm',SVC())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we created two steps: the first, called \"scaler\", is an instance of MinMaxScaler, and the second, called \"svm\", is an instance of SVC. Now, we can fit the pipeline, like\n",
    "any other scikit-learn estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:20:04.047441Z",
     "start_time": "2019-05-01T09:20:04.033441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model \n",
    "pipe.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, pipe.fit first calls fit on the first step (the scaler), then transforms the training data using the scaler, and finally fits the SVM with the scaled data. To evaluate on\n",
    "the test data, we simply call pipe.score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:20:25.451866Z",
     "start_time": "2019-05-01T09:20:25.439865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.95\n"
     ]
    }
   ],
   "source": [
    "# find the score in the test set  \n",
    "print(\"Test score: {:.2f}\".format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the score method on the pipeline first transforms the test data using the\n",
    "scaler, and then calls the score method on the SVM using the scaled test data. As you\n",
    "can see, the result is identical to the one we got from the code at the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pipeline, we reduced the\n",
    "code needed for our “preprocessing + classification” process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pipelines in Grid Searches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a pipeline in a grid search works the same way as using any other estimator. We\n",
    "define a parameter grid to search over, and construct a GridSearchCV from the pipeline\n",
    "and the parameter grid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specifying the parameter grid, there is a slight\n",
    "change, though. We need to specify for each parameter which step of the pipeline it\n",
    "belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both parameters that we want to adjust, C and gamma, are parameters of\n",
    "SVC, the second step. We gave this step the name \"svm\". The syntax to define a parameter\n",
    "grid for a pipeline is to specify for each parameter the step name, followed by __\n",
    "(a double underscore), followed by the parameter name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:20:52.170722Z",
     "start_time": "2019-05-01T09:20:52.163722Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'svm__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "               'svm__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:20:59.166566Z",
     "start_time": "2019-05-01T09:20:56.953944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'svm__C': [0.001, 0.01, 0.1, 1, 10, 100], 'svm__gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train with grid search \n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:21:01.432406Z",
     "start_time": "2019-05-01T09:21:01.400206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.98\n",
      "Test set score: 0.97\n",
      "Best parameters: {'svm__C': 1, 'svm__gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test)))\n",
    "print(\"Best parameters: {}\".format(grid.best_params_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to the grid search we did before, now for each split in the cross-validation,\n",
    "the MinMaxScaler is refit with only the training splits and no information is leaked\n",
    "from the test split into the parameter search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## The General Pipeline Interface "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The Pipeline class is not restricted to preprocessing and classification, but can in\n",
    "fact join any number of estimators together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For example, you could build a pipeline\n",
    "containing feature extraction, feature selection, scaling, and classification, for a total\n",
    "of four steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The only requirement for estimators in a pipeline is that all but the last step need to\n",
    "have a transform method, so they can produce a new representation of the data that\n",
    "can be used in the next step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Convenient Pipeline Creation with make_pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Creating a pipeline using the syntax described earlier is sometimes a bit cumbersome,\n",
    "and we often don’t need user-specified names for each step. There is a convenience\n",
    "function, **make_pipeline**, that will create a pipeline for us and automatically name\n",
    "each step based on its class. The syntax for make_pipeline is as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:23:33.460841Z",
     "start_time": "2019-05-01T09:23:33.455841Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "# standard syntax\n",
    "pipe_long = Pipeline([(\"scaler\", MinMaxScaler()), (\"svm\", SVC(C=100))])\n",
    "# abbreviated syntax\n",
    "pipe_short = make_pipeline(MinMaxScaler(), SVC(C=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The pipeline objects pipe_long and pipe_short do exactly the same thing, but\n",
    "pipe_short has steps that were automatically named. We can see the names of the\n",
    "steps by looking at the steps attribute: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:23:47.669652Z",
     "start_time": "2019-05-01T09:23:47.664651Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('svc', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False))]\n"
     ]
    }
   ],
   "source": [
    "# show pipeline stesps\n",
    "print(pipe_short.steps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The steps are named minmaxscaler and svc. In general, the step names are just lowercase\n",
    "versions of the class names. If multiple steps have the same class, a number is\n",
    "appended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:24:37.349749Z",
     "start_time": "2019-05-01T09:24:36.228935Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps:\n",
      "[('standardscaler-1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('standardscaler-2', StandardScaler(copy=True, with_mean=True, with_std=True))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), PCA(n_components=2), StandardScaler())\n",
    "print(\"Pipeline steps:\\n{}\".format(pipe.steps)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As you can see, the first StandardScaler step was named standardscaler-1 and the\n",
    "second standardscaler-2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Accessing Step Attributes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Often you will want to inspect attributes of one of the steps of the pipeline—say, the\n",
    "coefficients of a linear model or the components extracted by PCA. The easiest way to\n",
    "access the steps in a pipeline is via the named_steps attribute, which is a dictionary\n",
    "from the step names to the estimators: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:26:17.028291Z",
     "start_time": "2019-05-01T09:26:17.003289Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components.shape: (2, 30)\n"
     ]
    }
   ],
   "source": [
    "# fit the pipeline defined before to the cancer dataset\n",
    "pipe.fit(cancer.data)\n",
    "# extract the first two principal components from the \"pca\" step\n",
    "components = pipe.named_steps[\"pca\"].components_\n",
    "print(\"components.shape: {}\".format(components.shape)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Accessing Attributes in a Grid-Searched Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "one of the main reasons to use pipelines is for doing grid searches. A common task is to access some of the steps of a pipeline inside\n",
    "a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:29:05.314199Z",
     "start_time": "2019-05-01T09:29:05.282999Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#create pipeline with standardscaler and logistic regression algorithm \n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next, we create a parameter grid.The regularization parameter to tune for LogisticRegression is the parameter C. We use a logarithmic\n",
    "grid for this parameter, searching between 0.01 and 100.or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:30:30.873210Z",
     "start_time": "2019-05-01T09:30:30.857610Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10, 100]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:31:24.043860Z",
     "start_time": "2019-05-01T09:31:23.855251Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'logisticregression__C': [0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As usual, we split the cancer dataset into training and test sets, and fit a grid search:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=4)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:32:43.734238Z",
     "start_time": "2019-05-01T09:32:43.718638Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "# access the coefficients of the best LogisticRegression model that was found by GridSearchCV\n",
    "print(\"Best estimator:\\n{}\".format(grid.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To access the logisticregression step, we can use the\n",
    "named_steps attribute of the pipeline, as explained earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:34:31.124051Z",
     "start_time": "2019-05-01T09:34:31.092851Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression step:\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression step:\\n{}\".format( grid.best_estimator_.named_steps[\"logisticregression\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we have the trained LogisticRegression instance, we can access the coefficients\n",
    "(weights) associated with each input feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:35:38.776196Z",
     "start_time": "2019-05-01T09:35:38.743996Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression coefficients:\n",
      "[[-0.38856355 -0.37529972 -0.37624793 -0.39649439 -0.11519359  0.01709608\n",
      "  -0.3550729  -0.38995414 -0.05780518  0.20879795 -0.49487753 -0.0036321\n",
      "  -0.37122718 -0.38337777 -0.04488715  0.19752816  0.00424822 -0.04857196\n",
      "   0.21023226  0.22444999 -0.54669761 -0.52542026 -0.49881157 -0.51451071\n",
      "  -0.39256847 -0.12293451 -0.38827425 -0.4169485  -0.32533663 -0.13926972]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression coefficients:\\n{}\".format(grid.best_estimator_.named_steps[\"logisticregression\"].coef_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Grid-Searching Preprocessing Steps and Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using pipelines, we can encapsulate all the processing steps in our machine learning\n",
    "workflow in a single scikit-learn estimator. Another benefit of doing this is that we\n",
    "can now adjust the parameters of the preprocessing using the outcome of a supervised\n",
    "task like regression or classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:50:14.416171Z",
     "start_time": "2019-05-01T09:50:14.258964Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import boston dataset \n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "#load the dataset \n",
    "boston = load_boston()\n",
    "\n",
    "# split the boston dataset into train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target,\n",
    "random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:52:32.056041Z",
     "start_time": "2019-05-01T09:52:32.024841Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import polynoialfeatures  and ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge \n",
    "\n",
    "# create a pipeline\n",
    "pipe = make_pipeline(StandardScaler(), PolynomialFeatures(), Ridge()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How do we know which degrees of polynomials to choose, or whether to choose any\n",
    "polynomials or interactions at all? Ideally we want to select the degree parameter\n",
    "based on the outcome of the classification. Using our pipeline, we can search over the\n",
    "degree parameter together with the parameter alpha of Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:54:09.962365Z",
     "start_time": "2019-05-01T09:54:09.946765Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'polynomialfeatures__degree': [1, 2, 3],'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:55:00.868283Z",
     "start_time": "2019-05-01T09:54:54.257772Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('polynomialfeatures', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'polynomialfeatures__degree': [1, 2, 3], 'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the grid search again \n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can visualize the outcome of the cross-validation using a heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:58:42.425238Z",
     "start_time": "2019-05-01T09:58:42.041225Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1190a588>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcgAAAD3CAYAAACZ+sQmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAH7hJREFUeJzt3XuYXVWd5vHvm0BEuapBxSRIBiNORAUNF8WxRUUDrdC2lwG84UOLdIuXRu2BRxtp7FagRxydjgxBEXSEgPTYlhrNeGPwApiAgCRIE4OYAmwMICAqJFXv/LF3waE4VWfv1Dl1Tp3zfp5nP3X2Pmuv/VtQeX619l57LdkmIiIiHm1WtwOIiIjoRUmQERERTSRBRkRENJEEGRER0UQSZERERBNJkBEREU0kQUZERDSRBBkREdFEEmREREQTSZARERFNbNPtACIiYvC8+uDtfdfdI5XKXn39g6tsL+1wSI+RBBkREdNu090jXLVqfqWy2+72y7kdDqepJMiIiOgCM+LRbgcxqTyDjIiIaWdgFFfaqpC0VNJNktZLOqnJ97tL+oGkn0m6XtJhrepMDzIiIqadMZtd7RlkK5JmA8uAQ4BhYLWkIdvrGop9BLjE9tmSFgMrgT0mq7cve5AV/pJ4nKSLy++vkrRHw3cnl8dvkvTqhuPnSbpT0g3T04r6trbdkp5c/mX1e0n/Mt1xt0OFtr9U0jWStkh6Qzdi7KSZ8Ps5Fc3aJ+lJkr4j6eby5xO7GeNU1WmjCp8pf9+vl/SC7kW+9drYg9wfWG97g+2HgBXAEePKGNip/LwzcHurSvsuQTb8JXEosBg4qvxrodGxwD22nwl8CjijPHcxcCTwHGAp8NmyPoDzy2M9aSrtBv4E/D3wwWkKt60qtv3XwDHAhdMb3bQ5nx7+/WyD83ls+04Cvmd7EfC9cn8mO5/qbTwUWFRuxwFnT1OMbWNgBFfaKpgHbGzYHy6PNToVeIukYYre43taVdp3CZJqf0kcAVxQfr4UeIUklcdX2H7Q9i3A+rI+bF8O3D0dDdhKW91u2w/Y/hFFopyJWrbd9q9sXw/09qiArTQDfj+nZIL2Nf4+XwD8xbQG1WY123gE8EUXrgR2kbTb9ETaPjV6kHMlrWnYjhtXlZpUPz6zHgWcb3s+cBjwJUmT5sB+fAbZ7C+JAyYqY3uLpHuBJ5fHrxx37vi/QnrVVNq9aVoi7JwqbY/+81TbdwDYvkPSU7odUAdM1MaJekx3THN8W83AiKsNwAE22V4yyffDwIKG/fk89hbqsZQ9dNtXSNoOmAvcOVGl/diDrPKXxERlqpzbq6bS7pmuX9sVMZG++J0frbhVsBpYJGmhpDkUj8qGxpX5NfAKAEn/GdgO+O1klfZjgqzyl8TDZSRtQ/HA9u6K5/aqqbR7ppvJ/99i6/3H2G3F8ueEPYEZbKI2zvjfeVd8/ljlGaTtLcAJwCrgRorRqmslnSbp8LLYB4B3SroOuAg4xp68C9uPCbLKXxJDwNvLz28Avl/+hxoCjixHey6keAD+02mKe6qm0u6Zrkrbo/80/j6/HfhaF2PplInaOAS8rRzNeiBw79it2JnChs0Vt2r1eaXtZ9ne0/Y/lcdOsT1Ufl5n+yDbz7e9j+3/26rOvkuQFf+S+DzwZEnrgRMpR4bZXgtcAqwDvg282y5e1JF0EXAFsJekYUnHTme7WplKuwEk/Qo4CzimbN/4UaA9q0rbJe1Xjl57I3COpLXdi7j9ev33c6omaN/pwCGSbqZ4/+30bsY4VTXbuBLYQDGQ8Fzgb7oQ8hSJkYpb1yLsjw5ERETMJHs/b47/9ZvVplh99u53XN1ikE5H9OMo1oiImAG62TusIgkyIiKmXTFRQBJkRETEY4w6CTIiIuJR0oOMiIhowojNnt26YBf13WseW6PJvH59bZDaO0hthcFq7yC1FfqvvWM9yF5+zSMJstBXv3gVDFJ7B6mtMFjtHaS2Qt+1V4x4VqWtW3KLNSIipp2B0R7vo/VUgtzpSdt413mPm/brzn36HPZ87vYDM2PCILV3kNoKg9XebrV1pEsjL5/89DnssfcO097eW9c+sMn2rp2oO4N0ath13uM4/avP7nYYERETun90u26HMK2O3esnt3aiXltdvX1aRU8lyIiIGByj6UFGREQ8mhEPubdTUG9HFxERfSmDdCIiIibQrQFPVSVBRkTEtDNiJD3IiIiIxxrt8VGsvR1dRET0pWKquVmVtiokLZV0k6T1kk5q8v2nJF1bbv8u6Xet6kwPMiIipl07JyuXNBtYBhwCDAOrJQ3ZXvfw9ey/bSj/HmDfVvWmBxkREdPOpp1zse4PrLe9wfZDwArgiEnKHwVc1KrSJMiIiOgCMVpxq2AesLFhf7g89tirSs8AFgLfb1VpbrFGRMS0M9SZam6upDUN+8ttL2/Yb5ZFJ5q39kjgUtsjrS6aBBkREV1R4zWPTbaXTPL9MLCgYX8+cPsEZY8E3l3lokmQEREx7YwYbd9EAauBRZIWArdRJMGjxxeStBfwROCKKpUmQUZERFe0a6IA21sknQCsAmYD59leK+k0YI3tobLoUcAK25WWDUuCjIiIadfO1zwAbK8EVo47dsq4/VPr1JkEGRER0870/kw6SZAREdEVI1kPMiIi4tFs9VcPUtLjgd1t39SheCIiYkDUeA+yKypHJ+m1wLXAt8v9fSQNTX5WRETEYxULJrdtJp2OqNODPJVivrvLAGxfK2mPtkcUEREDQD3fg6yTILfYvlfq7YeqERHR+wxtfc2jE+okyBskHQ3MlrQIeC/wk86EFRER/azNM+l0RJ3+7XuA5wAPAhcC9wLv70RQERHR/0aZVWnrlso9SNt/AD4s6eO2H6hyjqTzgNcAd9reeytjjIiIPlOsB9knPUhJL5a0Drix3H++pM+2OO18YOnWhxcREf1q1Kq0dUudvuungFcDdwHYvg546WQn2L4cuHuro4uIiL5UPIOcVWnrlloTBdjeOG4Ua8sFJyMiIprpp6nmNkp6MWBJcyhGsd441QAkHQccBzD36XOmWl1ERMwARmwZ7e3XPOr0XY+nWIV5HsXqzftQcVXmydhebnuJ7SU7PSlTw0ZEDIq+mElH0mzgrbbf3OF4IiJiAPTNKFbbI8ARdSuXdBFwBbCXpGFJx9atIyIi+lM/DdL5saR/AS4GHn4P0vY1E51g+6gpxBYREX1qJsykUydBvrj8eVrDMQMvb184ERExKNr5fFHSUuDTwGzgc7ZPb1LmTRQLbxi4zvbRk9VZZyadg2tFGxERMQFD23qQ5TiZZcAhFINIV0sasr2uocwi4GTgINv3SHpKq3orJ0hJJzY5fC9wte1rq9YTERGB2/qax/7AetsbACStoBg3s66hzDuBZbbvAbB9Z6tK6zz9XELxqse8cjsOeBlwrqS/q1FPREQMuDYvmDwP2NiwP1wea/Qs4FmSfizpyvKW7KTqPIN8MvAC278HkPRR4FKK6eauBs6sUVdERAy4GrdY50pa07C/3Pbyhv1mFXnc/jbAIoqO3Xzgh5L2tv27iS5aJ0HuDjzUsL8ZeIbtP0p6sEY9EREx4Go+g9xke8kk3w8DCxr25wO3Nylzpe3NwC2SbqJImKsnqrROgrwQuFLS18r91wIXSdqeR9/njYiIaKmNr3msBhZJWgjcBhwJjB+h+m/AUcD5kuZS3HLdMFmldUaxfkzSSuAlFN3Z422PdXkzw05ERFTWzvcgbW+RdAKwiuI1j/Nsr5V0GrDG9lD53avKZRtHgA/ZvmuyeutOfvp44D7bX5C0q6SFtm+p35yIiBhohi1tnCXH9kpg5bhjpzR8NnBiuVVS5zWPj1KMZN0L+AKwLfC/gYOq1hEREQHtfQ+yU+r0IF8H7AtcA2D7dkk7diSqiIjoe/2UIB+ybUkGKAfnRERE1DYT5mKtcwP4EknnALtIeifwXeDczoQVERH9zlalrVvqjGL975IOAe6jeA55iu3vdCyyiIjoa91cDLmKWqNYy4SYpBgREVNi98EzSEn389gpex5me6e2RhQREQNAjIx2bzHkKlomSNs7ApQvXP4G+BLFRAFvBjKKNSIitko3ny9WUecW66ttH9Cwf7akq8gk5RERUdNMeA+yTv92RNKbJc2WNEvSmymm64mIiKjHxXPIKlu31EmQRwNvAv6j3N7IYyeDjYiIqKSN60F2RJ3XPH5FsUJzU5JOtv2JdgQVERH9zfT+M8h2DiF6YxvrioiIvlbMpFNl65a6q3lMprf/FIiIiJ4yOtrbaaOdCbKLj1IjImImKQbgDE6CnHJL52gLC7addP3KmKHmMNrtEKbVU2dv7nYI02q3bXbodgjT5p6R33Q7hGl1bAfr7vXXPNqZIC9pY10REdHnuvkKRxUZpBMREV3R66t5tDNB9nZfOSIieoaplhyrJkhJSyXdJGm9pJOafH+MpN9Kurbc/qpVnRmkExERXdGupCFpNrAMOAQYBlZLGrK9blzRi22fULXe9CAjImL6GTyqSlsF+wPrbW+w/RCwgkkmtqmqnQnyK22sKyIi+lwbb7HOAzY27A+Xx8Z7vaTrJV0qaUGrSisnSElnStpJ0raSvidpk6S3jH1v++NV64qIiKgxWflcSWsatuPGVdUsi46/g/t1YA/bzwO+C1zQKr46PchX2b4PeA1Fdn4W8KEa50dERACPzMVasQe5yfaShm35uOqGgcYe4Xzg9kddz77L9oPl7rnAC1vFWCdBblv+PAy4yPbdNc6NiIh4hAGr2tbaamCRpIWS5gBHAkONBSTt1rB7OHBjq0rrjGL9uqRfAH8E/kbSrsCfapwfERHxsHZNFGB7i6QTgFXAbOA822slnQassT0EvFfS4cAW4G7gmFb11lnu6iRJZwD32R6R9AfaMEooIiIGVBtfDrS9Elg57tgpDZ9PBk6uU2edQTpPAN4NnF0eejqwpM7FIiIiCtVe8aj4mkdH1HkG+QXgIeDF5f4w8I9tjygiIvqf+2uquT1tnwlsBrD9RzI5QEREbC1X3LqkziCdhyQ9njJcSXsCD05+SkRExER6u49VJ0F+FPg2sEDSl4GDqDAKKCIioqken8G7UoKUJOAXwF8CB1Kk/ffZ3tTB2CIiop/1Q4K0bUn/ZvuFwDc7HFNERPS7crLyXlZnkM6VkvbrWCQRETFY+miQzsHAuyTdCjxAcZvV5cSvERER9XTxFY4q6iTIQzsWRUREDBz1wzPIUo83JSIiZowu3z6tok6C/CZFcwRsBywEbgKe04G4IiKir1VeqaNr6kxW/tzGfUkvAN7V9ogiImIw9FEP8lFsX5NRrRERsdVGux3A5ConSEknNuzOAl4A/LbFOQuALwJPo/hPsdz2p7cizoiI6CdjCyb3sDo9yB0bPm+heCb5ry3O2QJ8oOxt7ghcLek7ttfVjDMiIvpMP41iXWf7K40HJL0R+MoE5bF9B3BH+fl+STcC84AkyIiIQdfjCbLOTDrNVmKuvDqzpD2AfYGralwzIiKiK1r2ICUdChwGzJP0mYavdqK4hdqSpB0obse+3/Z94747DjgO4GnzZlcMOyIiZrp23mKVtBT4NDAb+Jzt0yco9waKO5/72V4zWZ1VepC3A2uAPwFXN2xDwKsrBL0tRXL8su3/M/5728ttL7G9ZJcnJUFGRAwMq9rWgqTZwDKKGd8WA0dJWtyk3I7Ae6l4J7NlD9L2dcB1ki60vblKpQ3BCPg8cKPts+qcGxERfcy08zWP/YH1tjcASFoBHMFjx7t8DDgT+GCVSus8g9xD0qWS1knaMLa1OOcg4K3AyyVdW26H1bhmRET0KbnaVsE8YGPD/nB57JFrSfsCC2x/o2p8dUaxfgH4KPApipU93kEx7dyEbP+oVZmIiBhQ1Z9BzpXU+Lxwue3lDfvN8szDtUuaRZG7jqkTXp0E+Xjb35Mk27cCp0r6IUXSjIiIqKd6gtxke8kk3w8DCxr251OMnxmzI7A3cFnx5I+nAUOSDp9soE6dBPmnMgvfLOkE4DbgKTXOj4iIAGrdPq1iNbBI0kKK3HQkcPTYl7bvBeY+fG3pMuCD7RjFOub9wBMoRgC9EHgL8PYa50dERDyiTaNYbW8BTgBWATcCl9heK+k0SYdvbXh1VvNYDVDcYfU7tvaCERERQFtn0rG9Elg57tgpE5R9WZU6K/cgJb1I0jqK7Iyk50v6bNXzIyIiGmm02tYtdW6x/g+KiQHugoffj3xpJ4KKiIg+V/EVj25OaF5rPUjbG8sRQGNG2htOREQMjB6frLxOgtwo6cWAJc2hGKxzY2fCioiIvtfjCbLOLdbjgXdTzE4wDOxT7kdERNQ242+xSjrD9n8DDrb95mmIKSIiouuq9CAPK1fkqLz2Y0REREuuuHVJlWeQ3wY2AdtLuo9izjuP/bS9Uwfji4iIfuTuvsJRRcsepO0P2d4Z+KbtnWzv2PhzGmKMiIh+1Ac9SABsH9HJQCIiYnCI7g7AqaLKIJ37eSSHj70EmVusERExNTM9QdrecToCiYiIAdLlVziqqDWTDoCkpwDbje3b/nVbI4qIiMHQ4wmyzmTlh0u6GbgF+H/Ar4BvdSiuiIjoc/00WfnHgAOBf7e9EHgF8OOORBUREf2vx0ex1kmQm23fBcySNMv2Dyimm4uIiKinanKcCa95AL+TtANwOfBlSXcCWzoTVkRE9LteH6RTpwd5BPBH4G8pZtf5JfDaTgQVEREDoMd7kJUTpO0HbI/Y3mL7AtufKW+5RkRE1NbO1TwkLZV0k6T1kk5q8v3xkn4u6VpJP5K0uFWdLROkpB+VP++XdN/4n9VCj4iIGKdNPUhJs4FlwKHAYuCoJgnwQtvPtb0PcCZwVqt6q0wU8JLyZ8cnDLjt59vz9wv36/RlIqLN9r66ztOamW1Wrz84a7uvdKTWNq/1uD+w3vYGAEkrKB4LrhsrYLuxQ7c9FVJvrYkCJD0RWNB4nu1r6tQREREBtPP54jxgY8P+MHDA+EKS3g2cCMwBXt6q0soJUtLHgGOADcDYq5uucpGIiIjxavQg50pa07C/3PbyxqqanPOY2m0vA5ZJOhr4CPD2yS5apwf5JmBP2w/VOCciIqK56glyk+0lk3w/THF3c8x84PZJyq8Azm510ToPDm4AdqlRPiIiYmLte81jNbBI0kJJc4AjgaHGApIWNez+OXBzq0rr9CA/AfxM0g3Ag2MHbR9eo46IiIi2ruZhe4ukE4BVwGzgPNtrJZ0GrLE9BJwg6ZXAZuAeWtxehXoJ8gLgDODnPPIMMiIiYuu0cUCw7ZXAynHHTmn4/L66ddZJkJtsf6buBSIiIprp5kodVdRJkFdL+gTFfd3GW6x5zSMiImrr9VdK6yTIfcufBzYcy2seERFRX5fnWa2icoK0fXAnA4mIiAHT4wmy8mseknaWdJakNeX2SUk7dzK4iIjoT6K9k5V3Qp33IM8D7qeYMOBNwH3AFzoRVEREDIAeX+6qzjPIPW2/vmH/HyRd2+6AIiJiMMi9fY+1Tg/yj5JeMrYj6SCKBZQjIiLqcfGaR5WtW+r0II8Hvlg+dxRwN8Xk5REREfX1dgey1ijW64DnS9qp3M9iyRERsdX65j1ISY8DXg/sAWwjFauL2D6tI5FFRER/65cECXwNuBe4moaZdCIiImrr8iscVdRJkPNtL+1YJBERMVh6PEHWGcX6E0nP7VgkERExMGbCRAF1epAvAY6RdAvFLVYBtv28jkQWERF9TaO93YWskyAP7VgUERExWPppsnLgPRSrNK/rVDARETE4en09yDrPIH8BnCvpKknHZ6LyiIiYkh6fi7VygrT9OdsHAW+jeBfyekkXSsoyWBERUVs7B+lIWirpJknrJZ3U5PsTJa2TdL2k70l6Rqs66/QgkTQbeHa5bQKuA06UtKJOPRERMeAM2NW2FsrctIxirMxi4ChJi8cV+xmwpBxYeilwZqt666wHeRZwE3AY8HHbL7R9hu3XAvtOcM52kn4q6TpJayX9Q9XrRUREf2vjZOX7A+ttb7D9ELACOKKxgO0f2P5DuXslML9VpXUG6dwAfKThAuODa+ZB4OW2fy9pW+BHkr5l+8oa142IiD4z9h5km8wDNjbsDwMHTFL+WOBbrSptmSAlvaD8eC3w7LE5WMfYvsb2vc3OtW3g9+XutuXW4wN7IyKi4yrePi3NlbSmYX+57eUN+xp/AhPkGklvAZYAf9bqolV6kJ+c5DsDL5/s5PLe8NXAM4Fltq+qcM2IiOhzNXqQm2wvmeT7YWBBw/584PbHXE96JfBh4M9st5xTvGWCtD2lUaq2R4B9JO0CfFXS3rZvaAj4OOA4gO14wlQuFRERM0n77ieuBhZJWgjcBhwJHN1YQNK+wDnAUtt3Vqm0znJX2wJ/Dby0PHQZcI7tzVXOt/07SZcBSymeZ44dXw4sB9hJT8rt14iIAdGuZ5C2t0g6AVgFzKaY1GatpNOANbaHgH8GdgC+Uj4q/LXtwyert84gnbMpniF+ttx/a3nsryY6QdKuwOYyOT4eeCVwRo1rRkREPzLQxrlYba8EVo47dkrD51fWrbNOgtzP9vMb9r8v6boW5+wGXFA+h5wFXGL7G3WDjIiI/tPrU83VSZAjkva0/UsASf8JGJnsBNvXM8E7khERMeCqj2LtijoJ8kPADyRtKPf3AN7R9ogiImIgdHOtxyrqTDX3Y4oRQKPldg5wRSeCioiIPld1ovIZsmDyF4H7gI+V+0cBXwLe2O6gIiKivxUz6fR2F7JOgtxr3CCdH1QYpBMREdFcjw/SqXOL9WeSDhzbkXQAxW3XiIiI2mRX2rqlTg/yAOBtkn5d7u8O3Cjp5xTTrj6v7dFFRER/stv6HmQn1EmQSzsWRUREDJxeH8VaOUHavrWTgURExIDpo0E6ERER7eH+mkknIiKifdKDjIiIaKK382MSZEREdEc/TRQQERHRHgZGkiAjIiIeRXR3EoAqkiAjIqI7kiAjIiKa6PEEWWcu1oiIiPYwjyye2GqrQNJSSTdJWi/ppCbfv1TSNZK2SHpDlTqTICMioivaNVm5pNnAMuBQYDFwlKTF44r9GjgGuLBqfLnFGhER3dG+W6z7A+ttbwCQtAI4Alj3yKX8q/K7yvP3JEFGRMT0s2G0bXPNzQM2NuwPU6xANSVJkBER0R3V8+NcSWsa9pfbXt6wrybnTLl7mgQZERFdUeM9yE22l0zy/TCwoGF/PnD71sY1JoN0IiKiO+xqW2urgUWSFkqaAxwJDE01vCTIiIiYfgZGXW1rVZW9BTgBWAXcCFxie62k0yQdDiBpP0nDwBuBcyStbVWv3EMvakr6LdCNhZnnApu6cN1uGaT2DlJbYbDaO0hthe619xm2d213pTtv9zS/ePe3Vyr77ZvPvLrFLdaO6KlnkJ34n1CFpDXd+I/fLYPU3kFqKwxWeweprdCn7e2hDlozPZUgIyJiQBgYadtrHh2RBBkREV1gcBLkTLC8dZG+MkjtHaS2wmC1d5DaCv3Y3h6/xZpRrMC4F0773iC1t7GtklZK2mV8GUmnSvrg9Eb2qOv/vh1lYHD/3w6CvmtvG0exdkp6kDEQJAl4jd3j93QiBkl6kBHdIWkPSTdK+ixwDTAiaW753YfLpXG+C+zVcM5+kq6XdIWkf5Z0Q3l8drm/uvz+XTVj2UHS98rldn4u6YgmZV4m6XJJX5W0TtL/kjSr4ft/knSdpCslPbU89lpJV0n6maTvjh2PmBHaN1FARyRBRr/bC/ii7X0p37GV9EKKmTb2Bf4S2K+h/BeA422/CBhpOH4scK/t/cry75S0sEYcfwJeZ/sFwMHAJ8te7Xj7Ax8AngvsWcYHsD1wpe3nA5cD7yyP/wg4sGzfCuDvasQU0T02jIxU27okt1ij391q+8pxx/4L8FXbfwCQNFT+3AXY0fZPynIXAq8pP78KeF7DQqs7A4uAWyrGIeDjkl5KMUXzPOCpwG/Glftpw5I9FwEvAS4FHgK+UZa5Gjik/DwfuFjSbsCcGvFEdF+P32JNgox+98AEx5v9y2zWo2v87j22V21lHG8GdgVeaHuzpF8B21WIa2x/sx+Z9mqER/7t/k/gLNtDkl4GnLqV8UVMvx5PkLnFGoPocuB1kh4vaUfgtQC27wHul3RgWe7IhnNWAX8taVsASc+StH2Na+4M3Fkmx4OBZ0xQbv9ywuVZwH+luIXaqt7bys/V5u2K6AkVR7BmFGvE9LF9jaSLgWspnkv+sOHrY4FzJT0AXAbcWx7/HLAHcE357PC3wF/UuOyXga+Xa9pdC/xignJXAKdTPIO8HPhqi3pPBb4i6TbgSqDOc9GI7jH0+qDynpqsPKLbJO1g+/fl55OA3Wy/b5qu/TLgg7Zf06psxEy38za7+kU7Vfsbc9U9n8tk5RE94M8lnUzxb+NW4JjuhhPRx3q8g5YEGdHA9sXAxVXKSnou8KVxhxcAG8cde9D2ARWufRnFbd2I/jf2mkcPS4KM2Eq2fw7s0+04ImYqj/b2M8gkyIiI6ILuzpJTRRJkRERMv7HJyntY3oOMiIju8Gi1rQJJS8v5ldeXI9DHf/84SReX318laY9WdSZBRkTEtDPgUVfaWpE0G1gGHAosBo6StHhcsWOBe2w/E/gUcEarepMgIyJi+tnt7EHuD6y3vcH2QxQT949fMecI4ILy86XAKyZYMOBheQYZERFd4fa95jGPR79eNQyMf7Xq4TK2t0i6F3gysGmiSpMgIyJi2t3PPau+60vnViy+XTlN45jltpc37DfrCY6/N1ulzKMkQUZExLSzvbSN1Q1TTNIxZj5w+wRlhiVtQzHR/92TVZpnkBERMdOtBhaVK+HMoViJZ2hcmSEeWfHmDcD33WIy8vQgIyJiRiufKZ5AsSzdbOA822slnQassT0EfB74kqT1FD3HIyeusZDVPCIiIprILdaIiIgmkiAjIiKaSIKMiIhoIgkyIiKiiSTIiIiIJpIgIyIimkiCjIiIaCIJMiIioon/D94hSZebMFV4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.matshow(grid.cv_results_['mean_test_score'].reshape(3, -1),\n",
    "vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"ridge__alpha\")\n",
    "plt.ylabel(\"polynomialfeatures__degree\")\n",
    "\n",
    "plt.xticks(range(len(param_grid['ridge__alpha'])), param_grid['ridge__alpha'])\n",
    "plt.yticks(range(len(param_grid['polynomialfeatures__degree'])),\n",
    "param_grid['polynomialfeatures__degree'])\n",
    "\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looking at the results produced by the cross-validation, we can see that using polynomials\n",
    "of degree two helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T09:59:44.284011Z",
     "start_time": "2019-05-01T09:59:44.268411Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'polynomialfeatures__degree': 2, 'ridge__alpha': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T10:04:47.654966Z",
     "start_time": "2019-05-01T10:04:47.620765Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set score: 0.77\n"
     ]
    }
   ],
   "source": [
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test, y_test)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Searching over preprocessing parameters together with model parameters is a very\n",
    "powerful strategy. However, keep in mind that GridSearchCV tries all possible combinations\n",
    "of the specified parameters. Therefore, adding more parameters to your grid\n",
    "exponentially increases the number of models that need to be built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Grid-Searching Which Model To Use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can even go further in combining GridSearchCV and Pipeline: it is also possible\n",
    "to search over the actual steps being performed in the pipeline (say whether to use\n",
    "StandardScaler or MinMaxScaler). This leads to an even bigger search space and\n",
    "should be considered carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We want\n",
    "two steps, one for the preprocessing and then a classifier. We can instantiate this\n",
    "using SVC and StandardScaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T10:11:53.265296Z",
     "start_time": "2019-05-01T10:11:53.249696Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', SVC())]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can define the parameter_grid to search over. We want the classifier to\n",
    "be either RandomForestClassifier or SVC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To assign an estimator\n",
    "to a step, we use the name of the step as the parameter name. When we wanted to\n",
    "skip a step in the pipeline (for example, because we don’t need preprocessing for the\n",
    "RandomForest), we can set that step to None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T10:17:55.399367Z",
     "start_time": "2019-05-01T10:17:55.390367Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = [\n",
    "{'classifier': [SVC()], 'preprocessing': [StandardScaler(), None],\n",
    "'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "{'classifier': [RandomForestClassifier(n_estimators=100)],\n",
    "'preprocessing': [None], 'classifier__max_features': [1, 2, 3]}] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can instantiate and run the grid search as usual, here on the cancer dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T10:18:46.566508Z",
     "start_time": "2019-05-01T10:18:46.555507Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# split the dataset into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T10:19:16.253942Z",
     "start_time": "2019-05-01T10:19:07.621071Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocessing', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'classifier': [SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)], 'preprocessing': [StandardScaler(copy=True, with...=0,\n",
       "            warm_start=False)], 'preprocessing': [None], 'classifier__max_features': [1, 2, 3]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T10:19:36.532699Z",
     "start_time": "2019-05-01T10:19:36.518699Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'classifier': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 0.01, 'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True)}\n",
      "\n",
      "Best cross-validation score: 0.99\n",
      "Test-set score: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The outcome of the grid search is that SVC with StandardScaler preprocessing, C=10,\n",
    "and gamma=0.01 gave the best result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**NOTE:** Be careful not to overcomplicate your processes, and make sure to\n",
    "evaluate whether every component you are including in your model is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T10:27:32.691819Z",
     "start_time": "2019-05-01T10:27:32.687819Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Resources "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T10:28:41.640095Z",
     "start_time": "2019-05-01T10:28:41.624495Z"
    },
    "hidden": true
   },
   "source": [
    "Book of A. C. Muller and S. Guido - Introduction to Machine Learning with Python - 2017-ilovepdf-compressed - Chapter 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
